# -*- coding: utf-8 -*-
"""Water_Portabiity.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kY9Eq7Qxvzg3FS67LtGyNqIL7qzq_Gkr
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv("/content/water_potability.csv")
df.head()

df.tail()

df.columns

df.describe()

df.shape

df.isnull().sum()

plt.figure(figsize=(12,8))
sns.heatmap(df.isnull())

plt.figure(figsize=(12,8))
sns.heatmap(df.corr(),annot=True)

df["Potability"].value_counts()

#visulaization of dataset and finding the outlier
fig, ax = plt.subplots(ncols = 5, nrows = 2, figsize = (20,10))
ax = ax.flatten()

index = 0
for col,values in df.items():
  sns.boxplot(y=col,data=df,ax=ax[index])
  index += 1

sns.pairplot(df)

"""Handling Missing Values"""

df["ph"] = df["ph"].fillna(df["ph"].mean())
df["Sulfate"] = df["Sulfate"].fillna(df["Sulfate"].mean())
df["Trihalomethanes"] = df["Trihalomethanes"].fillna(df["Trihalomethanes"].mean())

"""Data Preprocessing"""

x = df.drop("Potability", axis = 1)
y = df["Potability"]

x.shape

y.shape

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)

from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()

x_train_scaled = scaler.fit_transform(x_train)
x_test_scaled=scaler.transform(x_test)

x_train_scaled.shape, x_test_scaled.shape

"""# Logistic Regression"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

model_lr = LogisticRegression()

model_lr.fit(x_train_scaled,y_train)

pred_lr = model_lr.predict(x_test_scaled)

accuracy_score_lr = accuracy_score(y_test,pred_lr)
accuracy_score_lr

"""Decision Tree Classifier"""

from sklearn.tree import DecisionTreeClassifier
model_dt = DecisionTreeClassifier(max_depth = 4)

model_dt.fit(x_train_scaled,y_train)

#making the predictions
pred_dt = model_dt.predict(x_test_scaled)

accuracy_score_dt = accuracy_score(y_test,pred_dt)
accuracy_score_dt

"""
Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier
#Creating the object
model_rf = RandomForestClassifier()

# Training the model
model_rf.fit(x_train_scaled,y_train)

#making prediction
pred_rf = model_rf.predict(x_test_scaled)

#accuracy acore
accuracy_score_rf = accuracy_score(y_test,pred_rf)
accuracy_score_rf

"""KNeighbours Classifiers"""

from sklearn.neighbors import KNeighborsClassifier
#Creating the model object
model_knn = KNeighborsClassifier()

for i in range(4,15):
  model_knn = KNeighborsClassifier(n_neighbors = i)
  model_knn.fit(x_train_scaled,y_train)
  pred_knn = model_knn.predict(x_test_scaled)
  accuracy_score_knn = accuracy_score(y_test,pred_knn)
  print(i, accuracy_score_knn)

#i = 11 gives the best accuracy
model_knn = KNeighborsClassifier(n_neighbors = 11)
model_knn.fit(x_train_scaled,y_train)
pred_knn = model_knn.predict(x_test_scaled)
accuracy_score_knn = accuracy_score(y_test,pred_knn)
print(accuracy_score_knn)

"""Support Vector Machines"""

from sklearn.svm import SVC
#creating the model object
model_svm = SVC(kernel="rbf")

model_svm.fit(x_train_scaled,y_train)

#prediction
pred_svm = model_svm.predict(x_test_scaled)
pred_svm

#accuracy score
accuracy_svm = accuracy_score(y_test,pred_svm)
accuracy_svm

"""Accuracy Visulaization"""

models = pd.DataFrame({
    "Model":[
        "Logistic Regression",
        "Decision Tree",
        "Random Forest",
        "KNN",
        "SVM" ],
    "Accuracy Score":[
        accuracy_score_lr,
        accuracy_score_dt,
        accuracy_score_rf,
        accuracy_score_knn,
        accuracy_svm
    ]

})

print(models)

sns.barplot(x="Accuracy Score", y="Model",data=models)
models.sort_values(by="Accuracy Score", ascending = False)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

model= Sequential()

model.add(LSTM(64,input_shape=(x_train_scaled.shape[1],1)))
model.add(Dropout(0.2))
model.add(Dense(32,activation='relu'))
model.add(Dense(1,activation='relu'))

model.fit(x_train_scaled,y_train,epochs=10,batch_size=32)

from tensorflow.keras.losses import BinaryCrossentropy
from tensorflow.keras.optimizers import Adam
model.compile(loss=BinaryCrossentropy(),optimizer=Adam(learning_rate=0.01),metrics=["accuracy"])

pred_lstm=(model.predict(x_test_scaled))

y_test =y_test.astype(np.float32)

pred_lstm_binary = (pred_lstm > 0.5).astype(int)
accuracy_LSTM = accuracy_score(y_test, pred_lstm_binary)

accuracy_LSTM

from sklearn.metrics import mean_squared_error , r2_score

mse = mean_squared_error(y_test, pred_lstm)
r2 = r2_score(y_test, pred_lstm)

print(mse)
print(r2)

